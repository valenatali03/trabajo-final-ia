import os
import json
from structs import Dataset
from const import MAX_WORDS, MIN_WORDS

ARCHIVO_DATASET = "steam_reviews.json"

def limpiar_reviews_por_longitud(dataset: Dataset, min_words, max_words) -> Dataset:
    """
    Filtra el dataset para eliminar reviews que contienen:
    1. Solo una palabra.
    2. M치s de MAX_WORDS (25) palabras.
    """
    reviews_iniciales = len(dataset)
    reviews_conservadas: Dataset = []
    reviews_eliminadas_min = 0
    reviews_eliminadas_max = 0

    print(f"Iniciando limpieza. Total de reviews iniciales: {reviews_iniciales}")
    print(f"Criterio: Conservar reviews entre {min_words} y {max_words} palabras.")

    for review_item in dataset:
        review_text = review_item["review"].strip()

        word_count = len(review_text.split())

        if word_count < min_words:
            reviews_eliminadas_min += 1
            continue

        if word_count > max_words:
            reviews_eliminadas_max += 1
            continue

        # si pasa ambos filtros, se conserva
        reviews_conservadas.append(review_item)

    reviews_eliminadas_total = reviews_eliminadas_min + reviews_eliminadas_max

    print("--- Resultados del Filtrado ---")
    print(f"Reviews eliminadas (1 palabra): {reviews_eliminadas_min}")
    print(f"Reviews eliminadas (M치s de {max_words} palabras): {reviews_eliminadas_max}")
    print(f"Reviews eliminadas (Total): {reviews_eliminadas_total}")
    print(f"Reviews conservadas (final): {len(reviews_conservadas)}")

    return reviews_conservadas

# Carga el dataset, lo limpia y lo guarda.
def ejecutar_limpieza(min_words, max_words):

    if not os.path.exists(ARCHIVO_DATASET):
        print(f"Error: No se encontr칩 el archivo de dataset: {ARCHIVO_DATASET}")
        print("Por favor, ejecuta 'dataset.py' primero para crear el archivo.")
        return

    # cargar el dataset
    print(f"Cargando dataset desde {ARCHIVO_DATASET}...")
    with open(ARCHIVO_DATASET, "r", encoding="utf-8") as f:
        dataset_crudo = json.load(f)

    # limpiar el dataset
    dataset_limpio = limpiar_reviews_por_longitud(dataset_crudo, min_words, max_words)

    # guardar el dataset limpio (sobrescribe el original)
    print(f"\nGuardando dataset limpio en {ARCHIVO_DATASET}...")
    with open(ARCHIVO_DATASET, "w", encoding="utf-8") as f:
        json.dump(dataset_limpio, f, ensure_ascii=False, indent=2)

    print("Proceso de limpieza completado.")
    print(f"Tama침o final del archivo: {len(dataset_limpio)}")


if __name__ == "__main__":
    ejecutar_limpieza(MIN_WORDS, MAX_WORDS)
